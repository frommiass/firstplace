#!/usr/bin/env python3
"""
–ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏
"""
import json
import sys
import os

os.environ['CUDA_VISIBLE_DEVICES'] = ''
sys.path.append('src')

from submit.interfaces import Message
from submit.model_inference import SubmitModelWithMemory

def load_dialogues_from_json(file_path: str):
    dialogues = []
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            try:
                data = json.loads(line)
                if isinstance(data, dict) and 'question' in data and 'sessions' in data:
                    dialogues.append(data)
            except:
                continue
    return dialogues

def convert_to_messages_safe(dialogue_messages):
    """
    –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –æ–±—ä–µ–∫—Ç—ã Message.
    
    –ò–°–ü–†–ê–í–õ–ï–ù–û: content –º–æ–∂–µ—Ç –±—ã—Ç—å float, int, None
    """
    messages = []
    for msg in dialogue_messages:
        # –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è content
        content = msg.get('content', '')
        if content is None:
            content = ''
        content = str(content)  # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –ª—é–±–æ–π —Ç–∏–ø –≤ —Å—Ç—Ä–æ–∫—É
        
        message = Message(
            content=content,
            role=msg.get('role', 'user'),
            session_id=str(msg.get('session_id', 'unknown'))
        )
        messages.append(message)
    
    return messages

def main():
    print("üß™ –¢–ï–°–¢ –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø –î–ï–î–£–ü–õ–ò–ö–ê–¶–ò–ò")
    print("=" * 60)
    
    # –ó–∞–≥—Ä—É–∑–∫–∞
    dialogues = load_dialogues_from_json("data/format_example.jsonl")
    dialogue = dialogues[1]  # –í—Ç–æ—Ä–æ–π –¥–∏–∞–ª–æ–≥
    dialogue_id = dialogue['id']
    question = dialogue['question']
    correct_answer = dialogue['ans']
    
    print(f"\n–î–∏–∞–ª–æ–≥: {dialogue_id}")
    print(f"–í–æ–ø—Ä–æ—Å: {question}")
    print(f"–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç: {correct_answer}")
    print(f"–°–µ—Å—Å–∏–π: {len(dialogue['sessions'])}")
    
    # –ü–æ–¥—Å—á–µ—Ç –æ–±—â–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–æ–æ–±—â–µ–Ω–∏–π
    total_messages = sum(len(s['messages']) for s in dialogue['sessions'])
    print(f"–í—Å–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {total_messages}")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
    print(f"\nü§ñ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏...")
    model = SubmitModelWithMemory(
        model_path="dummy_path",
        weights_dir="src/submit/weights"
    )
    
    # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ –ø–∞–º—è—Ç—å
    print(f"\nüìù –ó–∞–ø–∏—Å—å –≤ –ø–∞–º—è—Ç—å...")
    for i, session in enumerate(dialogue['sessions'], 1):
        messages = convert_to_messages(session['messages'])
        print(f"   –°–µ—Å—Å–∏—è {i}/{len(dialogue['sessions'])}: {len(messages)} —Å–æ–æ–±—â–µ–Ω–∏–π")
        model.write_to_memory(messages, dialogue_id)
    
    # Flush
    print(f"\nüîÑ Flush –±—É—Ñ–µ—Ä–∞...")
    if dialogue_id in model.write_buffer:
        model._flush_buffer(dialogue_id)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–∫–æ–ª—å–∫–æ —á–∞–Ω–∫–æ–≤ —Å–æ–∑–¥–∞–ª–æ—Å—å
    print(f"\n{'='*60}")
    print(f"üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´")
    print(f"{'='*60}")
    
    if dialogue_id in model.search_engine.dialogue_chunks:
        chunks = model.search_engine.dialogue_chunks[dialogue_id]
        print(f"\n‚úÖ –°–æ–∑–¥–∞–Ω–æ —á–∞–Ω–∫–æ–≤: {len(chunks)}")
        print(f"   –°–æ–æ–±—â–µ–Ω–∏–π –±—ã–ª–æ: {total_messages}")
        print(f"   –ü—Ä–æ—Ü–µ–Ω—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {len(chunks)/total_messages*100:.1f}%")
        
        # –ò—â–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ
        keywords = ['—Ñ—É—Ç–±–æ–ª', '–ø–∏–Ω–≥-–ø–æ–Ω–≥', '–ø–∏–Ω–≥', '–ø–æ–Ω–≥', '—Å–ø–æ—Ä—Ç']
        relevant = [c for c in chunks if any(kw in c.content.lower() for kw in keywords)]
        
        print(f"\nüîç –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤: {len(relevant)}")
        
        if relevant:
            print(f"\nüìã –†–ï–õ–ï–í–ê–ù–¢–ù–´–ï –ß–ê–ù–ö–ò:")
            for i, chunk in enumerate(relevant[:5], 1):
                print(f"\n{i}. {chunk.content}")
        
        # –ü–æ–∏—Å–∫
        print(f"\nüîé –ü–æ–∏—Å–∫...")
        search_results = model.search_engine.search(
            question=question,
            dialogue_id=dialogue_id,
            top_k=10
        )
        
        print(f"   –ù–∞–π–¥–µ–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {len(search_results)}")
        
        if search_results:
            print(f"   –õ—É—á—à–∏–π score: {search_results[0].final_score:.4f}")
            
            # –¢–æ–ø-3
            print(f"\n   –¢–æ–ø-3:")
            for i, result in enumerate(search_results[:3], 1):
                is_relevant = any(kw in result.chunk.content.lower() for kw in keywords)
                marker = "‚úì" if is_relevant else "‚úó"
                print(f"   {i}. {marker} [score={result.final_score:.4f}] "
                      f"{result.chunk.content[:80]}...")
            
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è
            print(f"\nü§ñ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞...")
            answer = model.answer_to_question(dialogue_id, question)
            print(f"   –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π: {answer}")
            print(f"   –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π: {correct_answer}")
    else:
        print(f"\n‚ùå –ß–∞–Ω–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –¥–ª—è –¥–∏–∞–ª–æ–≥–∞ {dialogue_id}")
    
    print(f"\n{'='*60}")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ DataProcessor
    if hasattr(model.data_processor, 'get_stats'):
        dp_stats = model.data_processor.get_stats()
        print(f"üìä DataProcessor —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {dp_stats['total_processed']}")
        print(f"   –ß–∞–Ω–∫–æ–≤: {dp_stats['total_chunks']}")
        print(f"   –û—à–∏–±–æ–∫: {dp_stats['errors']}")

if __name__ == "__main__":
    main()
